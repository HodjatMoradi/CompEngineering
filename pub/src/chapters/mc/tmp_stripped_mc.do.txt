

Monte Carlo Methods 
Monte Carlo methods are named after the Monte Carlo Casino in Monaco, this is because at its core it uses random numbers to solve problems. Monte Carlo methods are quite easy to program, and they are usually much more intuitive than a theoretical approach. If we would like to find the probability to get at least 5 on three dices after 5 throws there are methods from statistics that could tell us the probability. Using the Monte Carlo method, we would get the computer to pick a random integer between 1 and 6, three times, to represent one throw of the dices bla bla. later in this chapter 
Usually Usually we use differential equations to describe physical systems, the solution to these equations are continuous functions. In order for these solutions 
to be useful, they require that the differential equation describes our physical sufficiently. In many practical cases we have no control over many 
of the parameters entering the differential equation, or stated differently our system is not deterministic. This means that there could be some random fluctuations, occurring at different times and points in space, that we have no control over. In a practical situation we might would like to investigate how these fluctuations would affect the behavior of our system. A  o ray tracing

Monte Carlo Integration ''Hit and Miss'' 
Let us start with a simple illustration of the Monte Carlo Method (MCM), Monte Carlo integration. To the left in figure there is a shape of a pond. Imagine that we wanted to estimate the area of the pond, how could we do it? Assume further that you did not have your phone or any other electronic devices to help you. 
Two ponds to illustrate the MCM. 

One possible approach is: First to walk around it, and put up some bands (illustrated by the black dotted line). Then estimate the area inside the bands (g. 43 meters). Then we would know that the area was less than g. 12m. Finally, and this is the difficult part, throw rocks randomly inside the bands. The number of rocks hitting the pond divided by the total number rocks thrown should be equal to the area of the pond divided by the total area inside the bands, e. the area of the pond should be equal to:

It is important that we throw the rocks randomly, otherwise equation is not correct. Now, let us investigate this in more detail, and use the idea of throwing rocks to estimate. To the right in figure, there is a well known shape, a circle. The area of the circle is, and the shape is given by. Assume that the circle is inscribed in a square with sides of. To throw rocks randomly inside the square, is equivalent pick random numbers with coordinates, where and. We want all the and values to be chosen with equal probability, which is equivalent to pick random numbers from a uniform distribution. Below is a Python implementation:


In the table below, we have run the code for and different values of. 


 MC estimate Error 

 04 -10159 10 100 
 176 03441 10 032 
 1584 01681 10 010 
 14072 -00087 10 003 


We clearly see that a fair amount of rocks or numbers needs to be used in order to get a good estimate. If you run this code several times you will see that the results changes from time to time. This makes sense as the coordinates and are chosen at random. Random number generators 

There are much to be said about random number generators. The MCM depends on a good random number generator, otherwise we cannot use the results from statistics to develop our algorithms. Below, we briefly summarize some important points that you should be aware of: o Random number generators are generally of two types: hardware random number generator (HRNG) or pseudo random number generator (PRNG). o HRNG uses a physical process to generate random numbers, this could atmospheric noise, radioactive decay, microscopic fluctuations, which is translated to an electrical signal. The electrical signal is converted to a digital number (1 or 0), by sampling the random signal random numbers can be generated. The HRNG are often named true random number generators, and their main use are in cryptography. o PRNG uses a mathematical algorithm to generate an (apparent) random sequence. The algorithm uses an initial number, or a seed, to start the sequence of random number. The sequence is deterministic, and it will generate the same sequence of numbers if the same seed is used. At some point the algorithm will reproduce itself, e. it will have certain period. For some seeds the period may be much shorter. o Many of the PRNG are not considered to be cryptographically secure, because if a sufficiently long sequence of random numbers are generated from them, the rest of the sequence can be predicted. 
o Python uses the Mersenne Twister algorithm to generate random numbers, and has a period of. It is not considered to be cryptographically secure.

In Pythons function, a random seed is chosen each time the code is run, but if we set g, the code will generate the same sequence of numbers each time it is called. 

Encryption 
This section can be skipped as it is not relevant for development of the numerical algorithms, but it is a good place to explain the basic idea behind encryption of messages. A very simple, but not a very good encryption, is to replace all the letters in the alphabet with a number, g. A=1, B=2, C=3, etc. This is what is know as a substitution cipher, it does not need to be a number it could be a letter, a sequence of letters, letters and numbers etc. The receiver can solve the code by doing the reverse operation.

The weakness of this approach is that it can fairly easily be cracked, by the following approach: First we analyze the encrypted message and find the frequency of each of the symbols. Assume that we know that the message is written in English, then the frequency of symbols can be compared with the frequency of letters from a known English text (the most common is (12), then 
(9), etc.). We would then guess that the most occurring symbol probably is an or. When some of the letters are in place, we can compare with the frequency of words, and so on. By the help of computers this process can easily be automated.

A much better algorithm is to not replace a letter with the same symbol. To make it more clear, consider our simple example where A=1, B=2, C=3, . If we know say that A=1 but we add a random number, then our code would be much harder to crack. Then the letter A could be several places in the message but represented as a complete different number. Thus we could not use the frequency of the various symbols to crack the message.

How can the receiver decrypt the message? Obviously, it can be done if both the sender and receiver have the same sequence of random numbers (or the key). This can be achieved quite simple with random number generators, if we know the seed used we can generate the same sequence of random numbers. If Alice where to send a message to Bob without Eve knowing what it is, Alice and Bob could agree to send a message that was scrambled using Pythons Mersenne-Twister algorithm with seed=2.

The weakness of this approach is of course that Eve could convince Alice or Bob to give her the seed or the key. Another possibility is that Eve could write a program that tested different random number generators and seeds to decipher the message. How to avoid this?

Let us assume that Alice and Bob each had their own hardware random generator. This generator generated random numbers that was truly random, and the sequence could not be guessed by any outsider. Alice do not want to share her key (sequence of random numbers) with Bob, and Bob would not share his key with Alice. How can they send a message without sharing the key? One possible way of doing it is as follows: Alice write a message and encrypt it with her key, she send the message to Bob. Bob then encrypt the message with his key, he sends it back to Alice. Alice then decrypt the message with her key and send it back to Bob. Now, Bob can decrypt it with his own key and read the message. The whole process can be visualized by thinking of the message as box with the message. Alice but her padlock on the box (keeps her key for her self), she sends the message to Bob. Bob locks the box with his padlock, now there are two padlocks on the box. He sends the box back to Alice, Alice unlocks her padlock with her key, and sends it back to Bob. The box now only has Bob's key, he can unlock the box and read the message. The important point is that the box was never unlocked throughout the transaction, and Alice and Bob never had to share the key with anyone. 

Errors on Monte Carlo Integration and the Binomial Distribution 
How many rocks do we need to throw in order to reach a certain accuracy? To answer this question we need some results from statistics. Our problem of calculating the integral is closely related to the binomial distribution. When we throw a rock one of two things can happen i) the rock falls into the water, or ii) it falls outside the pond. If we denote the probability that the rock falls into the pond as, then the probability that it falls outside the pond has to be. This is simply because there are no other possibilities and the sum of the two probabilities has to be one. The binomial distribution is given by: is the probability that an event happens times after trials. The mean and the variance of the binomial distribution is:

Mean and variance The mean of a distribution is simply the sum divided by the count, the symbol or is usually used. For observations 
The mean is just an average, it could g. be the sum of all the heights of students in the class divided by the number of students. The mean would then be the average height of all the students in the class.

The variance is calculated by taking the difference between each of the data points and the mean, square it, and sum over all data points. Usually the symbol is used, . The variance measures the spread in the data. Furthermore, it squares the distance between the mean and the individual observations, meaning that the points lying far a way from contributes more to the variance. 

Before we proceed, we should take a moment and look a little more into the meaning of equation to appreciate its usefulness. A classical example of the use of the binomial formula is to toss a coin, if the coin is fair it will have an equal probability of giving us a head or tail, hence. Equation, can answer questions like: ''What is the probability to get only heads after 4 tosses?''. Let us calculate this answer using equation, the number of tosses is 4, the number of success is 4 (only heads each time)

''What is the probability to get three heads in four tosses?'', using the same equation, we find:

In figure, all the possibilities are shown. The number of possibilities are 16, and there are only one possibility that we get only heads, e. the probability is 1/16 as calculated in equation. In the figure we also see that there are 4 possible ways we can get three heads, hence the probability is 4/16=1/4 as calculated in equation. The famous Norwegian Moose coin, and possible outcomes of four coin flips in a row. 

Now, let us return to our original question, ''What is the error on our estimate of the integral, when using the MCM?''. Before we continue we should also clean up our notation, let be the value of the true integral, is our estimate of the integral, and is the area of the rectangle. First, let us show that the mean or expectation value of the binomial distribution is related to our estimate of the area of the pond or the circle, . In our case we draw 
random numbers, and times the coordinate falls inside the circle, equation tells us that the mean value is. 
is the probability that the coordinate is within the area to be integrated, hence as before is equal to the area to be integrated divided by the area of the total domain, thus: or

Equation, gives us an estimate of the variance of the mean value. Assume for simplicity that we can replace, this is of course only correct if the area of the rectangle is twice as big as our pond, but we are only interested in an estimate of the error, hence. We can now use the standard deviation as an estimate of the error of our integral:

In the last equation we have replaced with. 
Hence, the error of our integral is inversely proportional to the square root of the number of points. 

The mean value method 
How does our previous method compare with some of our standard methods, like the midpoint rule? The error for the MC method scales as in our previous error estimates we used the step length as an indicator of the accuracy, and not. The s is related to the number of points as, where and are the integration limit. Thus our MCM scales as, this is actually worse than the midpoint or trapezoidal rule, which scaled as.

The MCM can be improved. We will first describe the mean value method. In the last section we calculated the area of a circle by picking random numbers inside a square and estimated the fraction of points inside the circle. This is equivalent to calculate the area of a half circle, and multiply with 2:

The half-circle is now centered at the origin. Before we proceed we write our integral in a general form as:

Instead of counting the number of points inside the curve given by we could instead use the mean of the function, which we will define as:

Note that this formula is similar to the midpoint rule, but now the function is not evaluated at the midpoint, but at several points and we use the average value. 
Illustration of MC integration for. 

Below is an implementation:


In the table below we have compared the mean value method with the ''hit and miss'' method. We see that the mean value method performs somewhat better, but there are some random fluctuations and in some cases it performs poorer. 


 MC-mean Error MC Error 

 1706 0290 1600 0184 10 
 1375 -0041 1580 0164 10 
 1499 0083 1422 0006 10 
 1424 0008 1457 0041 10 
 1414 -0002 1422 0006 10 


We also see that in this case the error scales as.

At first sight it might be a little counter intuitive that if we multiply the average value of the function with the size of the integration domain we get an estimate for the integral, as illustrated in the top figure in figure. A different, but equivalent way, of viewing the mean value method is the lower figure in figure. For each random point we choose, we multiply with the area, as increases the area decreases and the mean value method approaches the midpoint algorithm. The reason the mean value method performs poorer is that we do not sample the function at regular intervals. The law of large numbers, ensures that our estimate approach the true value of the integral.


Basic Properties of Probability Distributions 
The MCM is closely tied to statistics, and it is important to have a basic understanding of probability density functions (PDF). In the previous section, we used a random number generator to give us random numbers in an interval. All the numbers are picked with an equal probability. Another way to state this is to say that: we draw
random numbers from an uniform distribution. Thus all the numbers are drawn with an equal probability. What is the value of ? That value is given from another property of PDF's, all PDF's must be normalized to 1. This is equivalent to state that the sum of all probabilities must be equal to one. Thus for a general PDF we must have:

A uniform distribution is given by: you can easily verify that. In the MCM we typically evaluate expectation values. The expectation value for a function is defined: specializing to a uniform distribution we get:

Rearranging this equation, we see that we can write the above equation as:

This equation is the same as equation, but in the previous section we never explained why the expectation value of was equal to the integral. The derivation above shows that is equal to the expectation value of 
only under the condition that we draw numbers from a uniform distribution.

To make this a bit more clearer, let us specialize to. In this case the expectation value is equal to the mean:

The mean of a distribution is a special case  follows directly from the definition of the variance: the reason that the mean value method usually performs better is that the leading coefficient is smaller. Why would we or anyone use MC integration? Monte Carlo integration performs much poorer than any of our previous methods. So why should we use it, or when should we use it? The strength of MC integration is only apparent when there is a large number of dimensions. 



A side step: checking convergence in large dimensions 
If you immediate understand or accept that MC integration is the preferred method in higher dimension, you can skip the following section.

If you read about MC integration in various books and online, you will encounter the statement highlighted in the last section: MC is superior in higher dimensions, because it always scales as. My experience on this matter is that I do not really understand it before I have tried it myself. In this section I will try and explain how I am thinking to prove the statement, or at least get convinced that it is probably true.

First of all, when people make the statement about dimensionality they do not mean spatial dimensions. Usually the dimensionality is about all the possible variable in the problem under consideration. If we are doing investment analysis, we would like to know the most probable outcome (expectation value) of our investment given the variation in all the relevant variables. The expectation value would then be a multidimensional integral. (Ray tracing example?) However, the point in this section is not do to pick a very interesting and relevant example, we just want to have a simple case where we can systematically change the number of dimension and compare with the true answer. What immediately comes to (my) mind is the volume of a hyper sphere (or an -ball), the volume of a hyper sphere is known: where is the number of dimensions is the gamma function, if is an integer then and You can easily verify that for respectively.

Next, we want to extend one of our 1D integration routines to higher dimension, and compare with the MC method. What we want to investigate is: if gets large enough, will the MC method perform better than the standard MC method? If yes, how large must be?

How do we attack this problem? Here is how I would do it: o Start simple. Code a simple example in 2 or 3D, check the result with an analytical formula o While coding the example in 2 or 3D, make sure that the code can (easily) be extended to higher dimensions. 
o Choose the simplest 1D integration technique, once the example is working you can switch to a more advanced method.

Let be the coordinates in a -dimensional space, e. in 3D. The formula for a hyper sphere with radius is:

We continue by specializing to (but keep the 
notation, because it is then easier to extend to higher dimensions). In Cartesian coordinates the volume of the sphere (centered in the origin), can be written:

We can always do the last integration, regardless of the number of dimensions:

Monte Carlo Integration of a Hyper Sphere 

Let us first do the MC integration, which is extremely simple to implement. We simply place the sphere inside a cube, and then count the number of points that hits inside the hyper sphere:



The code with the underscore, is used because we do not use the counter in the code. We could also written. We can also make an implementation of equation, using the sampling method:



The function, and defined below. In the next section we will extend the trapezoidal rule to higher dimension, and it is much more cumbersome than the MC integration. The code for the analytical result is:



Trapezoidal Integration of a Hyper Sphere 

How do we extend the methods introduced in the chapter on numerical integration to higher order dimensions? The trick is to call a one dimensional integration routine several times, to see it more clearly, we rewrite equation as: when integrating, we do it by dividing the x-axis from 
to into equal slices as before. We also need to evaluate for each value of, which is slightly more tricky, see figure for an illustration. 
Illustration of a 2D integration to evaluate the volume of a sphere.

The multi dimensional integral is done by placing a box around the sphere, and divide this box into equal boxes. If start the integration at because the integrand is zero. If we move one step to the left, we need to integrate from to. We see from the figure to the right in figure that the function is not defined for two first points. Thus we need to make sure that if we are outside the integration bounds the function is zero, this can be achieved by the following code:

Next, we need to make our implementation of the trapezoidal rule able to handle a function with more than one argument. To make it clearer, we show the original implementation below:

To achieve what we want we add two extra arguments to our implementation and, a list with the coordinates and which coordinate to integrate over, respectively:

Next, we need to do the outer integral, that is to basically replace the function call in the routine above with the trapezoidal rule:

Note the similarities between and. If we run the code with for the MC integration and for the trapezoidal rule, we actually get that the methods performs about the same - a relative error of. The reason we allow for 
points in the MC method (instead of), is that we did one of the integrations used in the trapezoidal rule analytically.

Error Analysis in higher dimensions In the chapter about numerical integration, we did an error analysis on the trapezoidal rule and found that it scaled as. As we see from the example above, a higher order integration is simply to do a series of 1D integrations in all the dimensions, thus the error term should be. If we use the same spatial resolution in all dimensions, then the overall error scale as. If we let denote the number of points in each directions the total number of points used is. Thus, the error term scales as, and we see that if, the MC integration is expected to perform better. 


To continue our discussion, we can easily extend our code to higher dimensions, the case would be:

The code can be run by entering


Recursive Calls in Python 
As you might guess from reading the above, there must be a simpler way to extend our code to higher dimensions. As a rule of thumb: whenever you copy and paste code, think functions. The functions: are very similar and the only difference is that for the final integration is called and in we call the function to be integrated and not an integration routine. There are probably many ways to extend our code to higher dimensions, but we will use this opportunity to introduce recursive functions. A recursive function is simply a function that calls itself. Lets consider a very simple example, the factorial function, g. Below is an implementation that uses a loop:

Below is an equivalent implementation that uses recursive implementation:


Recursive functions Recursive implementation is very elegant, and more transparent, but it comes with a price. The reason is that when a function is called additional memory is allocated to store the local variables. If we where to calculate, 100 copies of the variable are created, whereas using a loop only one variable is created. Each time a function is called more memory is allocated, and if the recursive calls are too many it might cause memory overflow. If you try to call, Python will give an error, because the maximum number of recursions are reached, it can be changed by:


We can now extend our multi dimensional integration routine of the hyper sphere to any dimension, by using recursive function calls:

Importance Sampling 
What would be the optimal shape of the function for our MC method? Clearly if the function was uniform Assume that we would like to 

Exercise: The central limit theorem 


The central limit theorem is a corner stone in statistics, and it is the reason for why the normal distribution is so widely used. The central limit theorem states that if we calculate the average of an independent random variable, the average will be distributed according to a normal distribution. Not that the central limit theorem does not state anything about the distribution of the original variable. We will not prove the central limit theorem, but illustrate it with two examples. 





First we will investigate a random variable that follows a uniform distribution. Write a Python function that returns the average of uniformly distributed numbers in.






Calculate the average times and make a histogram of the values.






Repeat the above exercise for a Poisson distribution.






It is quite remarkable that the distribution of the average values from both a uniform and Poisson distribution follows a normal distribution. The general proof is not that complicated, but the ramifications are large. The central limit theorem explains why it makes sense to use the standard deviation as a measure of confidence for the mean value.

Exercise: Birthday Paradox 


The human mind is not good at logical thinking, and if we use our intuition we often get into trouble. A well known example is the ''Birthday Paradox'', it is simply to answer the following question: ''How many randomly selected people do we need in order that there is a 50\% chance that two of them have birthday on the same date?'' 





Write a Python function that pick a random date



Below are two examples, the first one picks a date, while the second one just picks a random day at year. 





Write a function that takes as argument, number of persons in a group, and returns 1 if two of them has birthday on the same date and 0 otherwise.











Write a function that returns the probability that two people in a group of persons have birthday on the same day, and determine how many people we need to have a probability of 50\%.


In order to get some statistics, we need to sample groups and return the fraction of groups that had two persons with the same birthday.

By trial an error, we find that 23 persons is needed in order to have a probability of 









