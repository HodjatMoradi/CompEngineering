





Numerical Integration 
Before diving into the details of this section, it is worth pointing out that the derivation of the algorithms in this section follows a general pattern: o We start with a mathematical model (in this case an integral) o The mathematical model is formulated in discrete form 
o Then we design an algorithm to solve the model 
o The numerical solution for a test case is compared with the true solution (could be an analytical solution or data) o Error analysis: we investigate the accuracy of the algorithm by changing the number of iterations and/or make changes to the implementation or algorithm

In practice you would not use your own implementation to calculate an integral, but in order to understand which method to use 
in a specific case, it is important to understand the limitation and advantages of the different algorithms. The only way to achieve this is to 
have a basic understanding of the development. There might also be some cases where you would like to adapt an integration scheme to your specific case if there is a special need that the integration is fast. 

The Midpoint Rule 
Numerical integration is encountered in numerous applications in physics and engineering sciences. 
Let us first consider the most simple case, a function, which is a function of one variable, . The most straight forward way of calculating the area is 
simply to divide the area under the function into equal rectangular slices with size, as illustrated in figure. The area of one box is: and the area of all the boxes is:

Note that the sum goes from, a total of elements. We could have chosen to let the sum go from. 
In Python, C, C++ and many other programming languages the arrays start by indexing the elements from to, 
therefore we choose the convention of having the first element to start at. Integrating a function with the midpoint rule. 

Below is a Python code, where this algorithm is implemented for 


There are many ways to calculate loops in a programming language. If you were coding in a lower level programming language like Fortran, C or C++, you would probably implement the loop like (in Python syntax):

However, in Python, you would always try to avoid loops because they are generally slow. A more efficient way of implementing the above rule would be to replace the loop with:




By increasing the numerical result will get closer to the true answer. How much do you need to increase in order to reach an accuracy higher than. What happens when increases?


The Trapezoidal Rule 
The numerical error in the above example is quite low, only about 2 for. 
However, by just looking at the graph above it seems likely that we can develop a better algorithm by using trapezoids instead of rectangles, 
see figure. Integrating a function with the trapezoidal rule. 

Earlier we approximated the area using the midpoint value. Now we use, where 
and, hence the area of one trapezoid is:

This is the trapezoidal rule, and for the whole interval we get:

Note that this formula was bit more involved to derive, but it requires only one more function evaluations compared to the midpoint rule. 
Below is a python implementation:


In the table below, we have calculated the numerical error for various values of.


 Error Midpoint Error Trapezoidal 

 1 14 -57\% 100\% 
 5 628 -66\% 31\% 
 10 314 -412\% 824\% 
 100 031 -11E-3\% 22E-3\% 



Note that we get the surprising result that this algorithm performs poorer, a factor of 2 than the midpoint rule. How can this be explained? By just looking at figure, we see that the midpoint rule actually over predicts the area from 
and under predicts in the interval or vice versa. The net effect is that for many cases the midpoint rule give a slightly better 
performance than the trapezoidal rule. In the next section we will investigate this more formally.

Numerical Errors on Integrals 
It is important to know the accuracy of the methods we are using, otherwise we do not know if the computer produce correct results. In the previous examples we were able to estimate the error because we knew the analytical result. However, if we know the 
analytical result there is no reason to use the computer to calculate the result(!). Thus, we need a general method to estimate the error, and let the computer 
run until a desired accuracy is reached. 

In order to analyze the midpoint rule in more detail we approximate the function by a Taylor 
series at the midpoint between and: 

Since and its derivatives are constants it is straight forward to integrate:

The first term is simply the midpoint rule, to evaluate the two other terms we make the substitution:

Note that all the odd terms cancels out, e for. Thus the error for the midpoint rule on this particular interval is: where we have ignored higher order terms. We can easily sum up the error on all the intervals, but clearly will 
not, in general, have the same value on all intervals. However, an upper bound for the error can be found by replacing 
with the maximal value on the interval, : where we have used. We can do the exact same analysis for the trapezoidal rule, but then we expand the function around instead of the midpoint. 
The error term is then:

At the first glance it might look like the midpoint rule always is better than the trapezoidal rule, but note that the second derivative is 
evaluated in different points ( and). Thus it is possible to construct examples where the midpoint rule performs poorer 
than the trapezoidal rule.

Before we end this section we will rewrite the error terms in a more useful form as it is not so easy to evaluate 
(since we do not know which value of to use). By taking a closer look at equation, 
we see that it is closely related to the midpoint rule for, hence:

The corresponding formula for the trapezoid formula is:

Now, we can make an algorithm that automatically choose the number of steps to reach (at least) a predefined accuracy:


In Python it is sometimes convenient to enter default values for the arguments in a function. In the above example, we could also have written the function definition as\\ \\ . If the parameter is not given the code will assume an accuracy of. 

Practical Estimation of Errors on Integrals 

From the example above we were able to estimate the number of steps needed to reach (at least) a certain precision. 
In many practical cases we do not deal with functions, but with data and it can be difficult to evaluate the derivative. 
We also saw from the example above that the algorithm gives a higher precision than what we asked for. 
How can we avoid doing too many iterations? A very simple solution to this question is to double the number of intervals until 
a desired accuracy is reached. The following analysis holds for both the trapezoid and midpoint method, because in both cases 
the error scale as. 

Assume that we have evaluated the integral with a step size, and the computed result is. 
Then we know that the true integral is, where is a constant that is unknown. If we now half the step size, 
then we get a new (better) estimate of the integral which is related to the true integral as. 
Taking the difference between and give us an estimation of the error: where we have used the fact that, Thus the error term is:

This might seem like we need to evaluate the integral twice as many times as needed. This is not the case, by choosing to exactly 
half the spacing we only need to evaluate for the values that lies halfway between the original points. We will demonstrate how 
to do this by using the trapezoidal rule, because it operates directly on the values and not the midpoint values. 
The trapezoidal rule can now be written as: in the last equation we have split the sum into odd an even values. The sum over the even values can be rewritten: note that is replaced with, we can now rewrite as:

Note that the first terms are actually the trapezoidal rule for, hence:

A possible algorithm is then: o Choose a low number of steps to evaluate the integral the first time, g. 
o Double the number of steps, 
o Calculate the missing values by summing over the odd number of steps 
o Check if is lower than a specific tolerance o If yes quit, if not, return to 2, and continue until is lower than the tolerance 

Below is a Python implementation:


What is a good number to start with, what happens if we choose too large? Compare the adaptive midpoint rule with the adaptive 
trapezoidal rule, is it possible to get the same accuracy with the same number of iterations? Check the expected number of 
iterations with the theoretical value.


If you compare the number of terms used in the adaptive trapezoidal rule, which was developed by halving the step size, and the adaptive midpoint rule that was derived on the basis of the theoretical error term, you will find the adaptive midpoint rule is more efficient. So why go through all this trouble? In the next section we will see that the development we did for the adaptive trapezoidal rule is closely related to Romberg integration, which is much more effective.

Romberg Integration 
The adaptive algorithm for the trapezoidal rule in the previous section can be easily improved by remembering 
that the true integral was given by: . The error term was in the previous example only used to 
check if the desired tolerance was achieved, but we could also have added it to our estimate of the integral to reach an accuracy to fourth order:

: Note that all odd powers of is equal to zero, thus the corrections are always in even powers. 


As before the error term, can be written as. Now we can proceed as in the previous section: First we estimate the 
integral by one step size, next we half the step size and use these two estimates to calculate the error term: but now we are in the exact situation as before, we have not only the error term but the correction up to order for this integral:

Each time we half the step size we also gain a higher order accuracy in our numerical algorithm. Thus, there are two iterations going on at the same time; 
one is the iteration that half the step size, and the other one is the increasing number of higher order terms added (which we will denote). 
We need to improve our notation, and replace the approximation of the integral with. Equation, can now 
be written:

A general formula valid for any can be found by realizing: where, as before. Subtracting equation and, we find an expression for the error term:

Then the estimate for the integral in equation is:

A possible algorithm is then: o Evaluate as the first estimate o Double the number of steps, or half the step size 
o Calculate the missing values by summing over the odd number of steps 
o Correct the estimate by adding all the higher order error term 
o Check if the error term is lower than a specific tolerance, if yes quit, if no goto 2, increase and by one The algorithm is illustrated in figure. Illustration of the Romberg algorithm. Note that for each new evaluation of the integral, all the correction terms (for) must be evaluated again. 

Note that the tolerance term is not the correct one as it uses the error estimate for the current step, 
which we also use correct the integral in the current step to reach a higher accuracy. 
Thus the error on the integral will always be lower than the user specified tolerance. Below is a Python implementation:


Note that the Romberg integration only uses 32 function evaluations to reach a precision of, whereas the adaptive midpoint and trapezoidal rule in the previous section uses 20480 and 9069 function evaluations, respectively. 

Gaussian Quadrature 
Many of the methods we have looked into are of the type: where the function is evaluated at fixed interval. For the midpoint rule for all values of, for the trapezoid rule 
for the endpoints and for all the interior points. 
For the Simpsons rule (see exercise) . 
Note that all the methods we have looked at so far samples the function in equal spaced points 
for. If we now allow for the function to be evaluated at unevenly spaced points, we can do a lot better. 
This realization is the basis for Gaussian Quadrature. We will explore this in the following, 
but to make the development easier and less cumbersome, we transform the integral from the domain to:

The factor in front comes from the fact that, thus we can develop our algorithms on the domain, 
and then do the transformation back using.


The idea we will explore is as follows: If we can approximate the function to be integrated on the domain (or on) as a 
polynomial of as large a degree as possible, then the numerical integral of this polynomial will be very close to the integral of the 
function we are seeking.

This idea is best understood by a couple of examples. Assume that we want to use in equation:

We now choose to be a polynomial of as large a degree as possible, but with the requirement that the integral is exact. If, we get: hence. If we choose, we get: hence. 

The Gaussian integration rule for is:

The Gaussian integration rule for is:





This equation is equal to the midpoint rule, by choosing we reproduce equation. If we choose: we can show that now can be integrated exact: hence there are four unknowns and four equations. The solution is: and.

The Gaussian integration rule for is:

The Gaussian integration rule for is:







The case N=3 
For the case, we find that can be integrated exactly: the solution to these equations are and. Below is a Python implementation:


Note that the Gaussian quadrature converges very fast. From to function evaluation we reduce the error (in this specific case) 
from 5% to 1%. Our standard trapezoidal formula needs more than 20 function evaluations to achieve this, the Romberg method uses 4-5 function evaluations. How can this be? If we use the standard Taylor formula for the function to be integrated, we know that for the Taylor 
formula must be integrated up to, so the error term is proportional to (where is some x-value in). 
is the step size, and we can replace it with, thus the error scale as (where is a constant). 
Following the same argument, we find for that the error term is or that the error term scale as. 
Each time we increase by a factor of one, the error term reduces by. Thus if we evaluate the integral for, 
increasing to will reduce the error by a factor of.

Error term on Gaussian Integration 
The Gaussian integration rule of order integrates exactly a polynomial of order. 
%if book: From Taylors error formula, see equation in Chapter, %else: From Taylors error formula, 
%endif we can easily see that the error term must be of order, and be proportional to, see for more details on the derivation of error terms. The drawback with an analytical error term derived from series expansion is that it involves the derivative of the function. As we have already explained, this is very unpractical and it is much more practical to use the methods described in section. Let us consider this in more detail, assume that we evaluate the integral using first a Gaussian integration rule with points, and then points. Our estimates of the "exact" integral would then be:

In principle, but in the following we will assume that, and. Subtracting equation and we can show that a reasonable estimate for the error term would be:

If this estimate is lower than a given tolerance we can be quite confident that the higher order estimate approximate the true integral within our error estimate. This is the method implemented in SciPy, 
Common Weight functions for Classical Gaussian Quadratures 

Which method to use in a specific case? 
There are no general answers to this question, and one need to decide from case to case. If computational speed is not an issue, 
and the function to be integrated can be evaluated at any points all the methods above can be used. If the function to be integrated 
is a set of observations at different times, that might be unevenly spaced, I would use the midpoint rule:

This is because we do not know anything about the function between the points, only when it is observed, and the formula uses only 
the information at the observation points. There is a second more subtle reason, and that is the fact that in many cases the 
observations a different times are the {\it average} value of the observable quantity and it those cases the midpoint 
rule would be the exact answer. 


Exercise: Numerical Integration 

Show that for a linear function, both the trapezoidal rule and the rectangular rule are exact


Consider for. The analytical result is. Use the Trapezoidal and 
Midpoint rule to evaluate these integrals and show that the error for the Trapezoidal rule is exactly twice as big as the Midpoint rule.


Use the fact that the error term on the trapezoidal rule is twice as big as the midpoint rule to derive Simpsons formula: Hint: (midpoint rule) and (trapezoidal rule).

Simpsons rule is an improvement over the midpoint and trapezoidal rule. It can be derived in different ways, we will make use of 
the results in the previous section. If we assume that the second derivative is reasonably well behaved on the interval 
and and fairly constant we can assume that, hence. we can now cancel out the error term by multiplying the first equation with 2 and adding the equations:

Now we can do as we did in the case of the trapezoidal rule, sum over all the elements: note that in the last equation we have changed the step size.



Show that for, the points and Gaussian quadrature rule for 
is  and  o Integrate using the rule derived in the exercise above and compare with the standard Gaussian quadrature rule for (, and).


Make a Python program that uses the Midpoint rule to integrate experimental data that are unevenly spaced and given in the form of two arrays. 



